{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c51b01-00c0-4290-873c-660459b88f9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# extract netcdf4 grid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd24ba79-ba9b-4ac9-8827-5ed4c38199d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from glob import glob \n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0c3fe7-d524-43b9-a7f2-f20cad3df6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = 'F:\\\\vm\\\\AVHRR-LTDR\\\\grid\\\\v1.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21f5fe0f-4c6d-4b58-aed8-e54f27ff86d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\vm\\AVHRR-LTDR\\grid\\v1.1\\Compressed\\1983.zip\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "zip_flist = glob(os.path.join(fdir, 'Compressed/*'))\n",
    "zip_flist.sort()\n",
    "print(zip_flist[1])\n",
    "print(len(zip_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a071188-fbb8-4700-b9a4-d99ad3ef71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path = os.path.join(fdir, 'extract')\n",
    "os.makedirs(extract_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00aff5-3b50-4501-8410-ca0646867a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for zip_file_path in zip_flist:\n",
    "    if zip_file_path.split('.')[-1].lower() != 'zip':  # skip if is not zip file\n",
    "        continue\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b3e52fc-126e-4f7e-a03c-5795a37e8fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n"
     ]
    }
   ],
   "source": [
    "unzip_flist = glob(os.path.join(extract_path, '*'))\n",
    "unzip_flist.sort()\n",
    "print(len(unzip_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00bc57ce-ede8-485f-b612-85f32698a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否每年的都解压出来了\n",
    "year_dict = {}\n",
    "for f in unzip_flist:\n",
    "    date = os.path.basename(f).split('-')[0]\n",
    "    year = date[:4]\n",
    "    if year in year_dict.keys():\n",
    "        year_dict[year].append(date)\n",
    "    else:\n",
    "        year_dict[year] = [date]\n",
    "for year in year_dict.keys():\n",
    "    if len(year_dict[year]) != 12:\n",
    "        print(f'Issue found with year: {year}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca327991-7a6e-46cd-94eb-18632ec14124",
   "metadata": {},
   "source": [
    "# 设置 dimension，variable, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8fd052-d838-435f-b9eb-19a4af2729c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from glob import glob \n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c1c9b4-9f56-4182-a5ce-3d1974c86bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = 'F:\\\\vm\\\\AVHRR-LTDR\\\\grid\\\\v1.1'\n",
    "extract_path = os.path.join(fdir, 'extract')\n",
    "unzip_flist = glob(os.path.join(extract_path, '*'))\n",
    "unzip_flist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1ac3811-f9b2-4b96-8dce-01285e319035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nc_attrs(nc_ds, config_file):\n",
    "    with open(config_file, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "    for line_raw in lines:\n",
    "        line = line_raw.strip()\n",
    "        attr_name = line.split(':')[0].strip()\n",
    "        attr_val_raw = ''.join(line.split(':')[1:])\n",
    "        attr_val = attr_val_raw.strip()\n",
    "        nc_ds.setncattr(attr_name, attr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "402643ea-dea8-489e-977c-96c7c37ac0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取变量定义并保存到文件中\n",
    "with nc.Dataset(unzip_flist[0],'r') as ds:\n",
    "    var_dict = ds.variables\n",
    "    # no quantization info for this variable\n",
    "    with open('./var_nc.txt','w') as fp:\n",
    "        for var in var_dict.keys():\n",
    "            fp.writelines(f'V==========V\\n')\n",
    "            fp.writelines(f'VAR:{var}\\n')\n",
    "            attr_keys = var_dict[var].ncattrs()\n",
    "            for attr_key in attr_keys:\n",
    "                attr_info = var_dict[var].getncattr(attr_key)\n",
    "                fp.writelines(f'{attr_key}:{attr_info}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e621efc6-9b71-4c0b-bdb6-5820cd5c1bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('lat', <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 720), ('lon', <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 1440), ('nv', <class 'netCDF4._netCDF4.Dimension'>: name = 'nv', size = 2), ('strlen', <class 'netCDF4._netCDF4.Dimension'>: name = 'strlen', size = 150), ('time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 1)])\n"
     ]
    }
   ],
   "source": [
    "with nc.Dataset(unzip_flist[0],'r') as ds:\n",
    "    # print(dir(ds))\n",
    "    # print(ds.title)\n",
    "    # print(ds.ncattrs())\n",
    "    # ds.title2 = 'shift'\n",
    "    # var_dict = ds.variables\n",
    "    # print(var_dict.keys())\n",
    "    # print(var_dict['time'])\n",
    "    # print(var_dict['lat'].dimensions)\n",
    "    print(ds.dimensions.items())\n",
    "    # dim_dict = ds.dimensions\n",
    "    # print(dim_dict.keys())\n",
    "    # print(dir(dim_dict['lat']))\n",
    "    # print(dim_dict['lat'].name)\n",
    "    # v = 'lon'\n",
    "    # print(var_dict[v])\n",
    "    # print(dir(var_dict[v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e960f255-51ae-4be1-96db-5baee5d0a4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\github\\\\avhrr_tools\\\\firecci'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb12637-8815-498f-8680-297705fb8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置attribute信息\n",
    "# 没用上\n",
    "def set_attr(ds_var, attr_name, attr_value):\n",
    "    if attr_name in ds_var.ncattrs():\n",
    "        ds_var.setncattr(attr_name, attr_value)\n",
    "        return\n",
    "    else:\n",
    "        ds_var.NonameAttribute = attr_value\n",
    "        ds_var.renameAttribute('NonameAttribute', attr_name)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "448799f1-eefe-4eb8-bbbc-4e95d88efa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nc.Dataset(unzip_flist[0],'r') as ds1:\n",
    "    dim_dict = ds1.dimensions\n",
    "    var_dict = ds1.variables\n",
    "    with nc.Dataset('./test1.nc','w', format='NETCDF4') as ds2:\n",
    "        # ?ds2.createDimension  # dimname, size=None)\n",
    "        # ?ds2.createVariable  # varname, datatype, dimensions=()\n",
    "        for dim_key in dim_dict.keys():\n",
    "            dimv = dim_dict[dim_key]\n",
    "            ds2.createDimension(dimname=dimv.name, size=dimv.size)\n",
    "        for var_key in var_dict.keys():\n",
    "            var_name = var_key\n",
    "            var = var_dict[var_key]\n",
    "            new_var = ds2.createVariable(\n",
    "                varname=var_name, \n",
    "                datatype=var.datatype, \n",
    "                dimensions=var.dimensions\n",
    "            )\n",
    "            new_var.setncatts({k: var.getncattr(k) for k in var.ncattrs()})\n",
    "            new_var[:] = var[:]\n",
    "            \n",
    "        ds2.title = 'combine file test'\n",
    "        ds2.setncattr('author','Yuhua Situ') #和上一行命令所用的方法等价\n",
    "        set_nc_attrs(ds2, './firecci_metadata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5f7c85-75c1-4fc4-a281-013b89a7cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./firecci_metadata.txt','r') as fp:\n",
    "    lines = fp.readlines()\n",
    "line = lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa37140-ce6a-4fd7-906a-5329a8e142ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'institution: University of Alcala'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a034d-84fe-4a86-9542-b2c78f41828e",
   "metadata": {},
   "source": [
    "# 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0919c5a-343f-41f2-b61c-c4c37c63ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from glob import glob \n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd0c606f-e797-4161-9565-7b4a0b3330ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = 'F:\\\\vm\\\\AVHRR-LTDR\\\\grid\\\\v1.1'\n",
    "extract_path = os.path.join(fdir, 'extract')\n",
    "unzip_flist = glob(os.path.join(extract_path, '*'))\n",
    "unzip_flist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbd5a9f-99b0-4a80-b831-5d8846508a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\vm\\AVHRR-LTDR\\grid\\v1.1\\extract\\19820101-ESACCI-L4_FIRE-BA-AVHRR-LTDR-fv1.1.nc\n",
      "F:\\vm\\AVHRR-LTDR\\grid\\v1.1\\extract\\20181201-ESACCI-L4_FIRE-BA-AVHRR-LTDR-fv1.1.nc\n"
     ]
    }
   ],
   "source": [
    "print(unzip_flist[0])\n",
    "print(unzip_flist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72ff8b98-eb65-4e2b-86ac-402f7539067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lat', 'lat_bnds', 'lon', 'lon_bnds', 'time', 'time_bnds', 'burned_area', 'standard_error', 'fraction_of_burnable_area', 'fraction_of_observed_area'])\n",
      "(1, 720, 1440)\n",
      "(1, 720, 1440)\n",
      "(1, 720, 1440)\n",
      "(1, 720, 1440)\n"
     ]
    }
   ],
   "source": [
    "with nc.Dataset(fpath, 'r') as ds:\n",
    "    print(ds.variables.keys())\n",
    "    print(ds.variables['burned_area'].shape)\n",
    "    print(ds.variables['standard_error'].shape)\n",
    "    print(ds.variables['fraction_of_burnable_area'].shape)\n",
    "    print(ds.variables['fraction_of_observed_area'].shape)\n",
    "    # a = ds.variables['burned_area'][:]\n",
    "    # b = np.moveaxis(a, [0,1,2], [2,1,0])\n",
    "    # print(a.shape)\n",
    "    # print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7902d03-a1b3-44e0-8b8d-f2cc50d5e15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year: 1982\n",
      "working on year: 1983\n",
      "working on year: 1984\n",
      "working on year: 1985\n",
      "working on year: 1986\n",
      "working on year: 1987\n",
      "working on year: 1988\n",
      "working on year: 1989\n",
      "working on year: 1990\n",
      "working on year: 1991\n",
      "working on year: 1992\n",
      "working on year: 1993\n",
      "working on year: 1995\n",
      "working on year: 1996\n",
      "working on year: 1997\n",
      "working on year: 1998\n",
      "working on year: 1999\n",
      "working on year: 2000\n",
      "working on year: 2001\n",
      "working on year: 2002\n",
      "working on year: 2003\n",
      "working on year: 2004\n",
      "working on year: 2005\n",
      "working on year: 2006\n",
      "working on year: 2007\n",
      "working on year: 2008\n",
      "working on year: 2009\n",
      "working on year: 2010\n",
      "working on year: 2011\n",
      "working on year: 2012\n",
      "working on year: 2013\n",
      "working on year: 2014\n",
      "working on year: 2015\n",
      "working on year: 2016\n",
      "working on year: 2017\n",
      "working on year: 2018\n"
     ]
    }
   ],
   "source": [
    "# 读取所有数据并且合并\n",
    "fpath_base = 'F:\\\\vm\\\\AVHRR-LTDR\\\\grid\\\\v1.1\\\\extract\\\\{Ymd}-ESACCI-L4_FIRE-BA-AVHRR-LTDR-fv1.1.nc'\n",
    "year = 1982\n",
    "fpath_list = []\n",
    "\n",
    "ind = 0\n",
    "date_list = []\n",
    "arr_burned_area = np.zeros( (1440, 720, len(unzip_flist)) )\n",
    "arr_ste = np.zeros( (1440, 720, len(unzip_flist)) )\n",
    "arr_burnable_frac = np.zeros( (1440, 720, len(unzip_flist)) )\n",
    "arr_obs_frac = np.zeros( (1440, 720, len(unzip_flist)) )\n",
    "\n",
    "coord_flag = True\n",
    "while year < 2019:\n",
    "    if year == 1994:\n",
    "        year += 1\n",
    "        continue\n",
    "    print(f'working on year: {year}')\n",
    "    for month in range(1, 13):\n",
    "        fpath = fpath_base.replace('{Ymd}', f'{year}{month:02d}01')\n",
    "        date_list.append(f'{year}{month:02d}01')\n",
    "        # 读取 netcdf4, 1440, 720, 1\n",
    "        # coords 'lat', 'lat_bnds', 'lon', 'lon_bnds'\n",
    "        # 'burned_area', 'standard_error', 'fraction_of_burnable_area', 'fraction_of_observed_area'\n",
    "        with nc.Dataset(fpath, 'r') as ds:\n",
    "            arr_burned_area[:,:,ind] = np.moveaxis(ds.variables['burned_area'][0,:,:], [0,1], [1,0])\n",
    "            arr_ste[:,:,ind] = np.moveaxis(ds.variables['standard_error'][0,:,:], [0,1], [1,0])\n",
    "            arr_burnable_frac[:,:,ind] = np.moveaxis(ds.variables['fraction_of_burnable_area'][0,:,:], [0,1], [1,0])\n",
    "            arr_obs_frac[:,:,ind]  = np.moveaxis(ds.variables['fraction_of_observed_area'][0,:,:], [0,1], [1,0])\n",
    "            \n",
    "            # 保存坐标信息，只需保存一次\n",
    "            if coord_flag:\n",
    "                coord_flag = False\n",
    "                coord_dict = {}\n",
    "                for key in ['lat','lat_bnds','lon','lon_bnds']:\n",
    "                    coord_dict[key] = ds.variables[key][:]\n",
    "        ind += 1\n",
    "        fpath_list.append(fpath)\n",
    "        \n",
    "    year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47ebcdb5-dbb3-4925-bc6d-e77551b7d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file='./coords.npy', arr=coord_dict, allow_pickle=True)\n",
    "\n",
    "np.save(file='./burned_area.npy', arr={'date':date_list, 'arr':arr_burned_area}, \n",
    "        allow_pickle=True)\n",
    "np.save(file='./ste.npy', arr={'date':date_list, 'arr':arr_ste}, \n",
    "        allow_pickle=True)\n",
    "np.save(file='./frac_burnable.npy', arr={'date':date_list, 'arr':arr_burnable_frac}, \n",
    "        allow_pickle=True)\n",
    "np.save(file='./frac_obs.npy', arr={'date':date_list, 'arr':arr_obs_frac}, \n",
    "        allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65454c95-5283-4da8-b4bd-086f73cc2caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unzip_flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08b17a0-aa6d-43a3-8ad0-b40f5d31b8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fpath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5235d050-8cc7-4125-9ab0-e449ef73c22e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lat': <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 720, 'lon': <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 1440, 'nv': <class 'netCDF4._netCDF4.Dimension'>: name = 'nv', size = 2, 'strlen': <class 'netCDF4._netCDF4.Dimension'>: name = 'strlen', size = 150, 'time': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 1}\n",
      "dict_keys(['lat', 'lat_bnds', 'lon', 'lon_bnds', 'time', 'time_bnds', 'burned_area', 'standard_error', 'fraction_of_burnable_area', 'fraction_of_observed_area'])\n",
      "[[4383. 4413.]]\n",
      "[[ 90.    89.75]\n",
      " [ 89.75  89.5 ]\n",
      " [ 89.5   89.25]\n",
      " ...\n",
      " [-89.25 -89.5 ]\n",
      " [-89.5  -89.75]\n",
      " [-89.75 -90.  ]]\n",
      "[[-180.   -179.75]\n",
      " [-179.75 -179.5 ]\n",
      " [-179.5  -179.25]\n",
      " ...\n",
      " [ 179.25  179.5 ]\n",
      " [ 179.5   179.75]\n",
      " [ 179.75  180.  ]]\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 burned_area(time, lat, lon)\n",
      "    units: m2\n",
      "    standard_name: burned_area\n",
      "    long_name: total burned_area\n",
      "    cell_methods: time: sum\n",
      "unlimited dimensions: time\n",
      "current shape = (1, 720, 1440)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "with nc.Dataset(unzip_flist[0],'r') as ds1:\n",
    "    dim_dict = ds1.dimensions\n",
    "    print(dim_dict)\n",
    "    print(ds1.variables.keys())\n",
    "    print(ds1.variables['time_bnds'][:])\n",
    "    print(ds1.variables['lat_bnds'][:])\n",
    "    print(ds1.variables['lon_bnds'][:])\n",
    "    print(ds1.variables['burned_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de8b81a-99e6-4a95-86e1-0af1b4c489b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存合并的数据到 netcdf 文件。暂不执行此操作。\n",
    "with nc.Dataset(unzip_flist[0],'r') as ds1:\n",
    "    dim_dict = ds1.dimensions\n",
    "    var_dict = ds1.variables\n",
    "    with nc.Dataset('./test1.nc','w', format='NETCDF4') as ds2:\n",
    "        # ?ds2.createDimension  # dimname, size=None)\n",
    "        # ?ds2.createVariable  # varname, datatype, dimensions=()\n",
    "        for dim_key in dim_dict.keys():\n",
    "            dimv = dim_dict[dim_key]\n",
    "            ds2.createDimension(dimname=dimv.name, size=dimv.size)\n",
    "        for var_key in var_dict.keys():\n",
    "            var_name = var_key\n",
    "            var = var_dict[var_key]\n",
    "            new_var = ds2.createVariable(\n",
    "                varname=var_name, \n",
    "                datatype=var.datatype, \n",
    "                dimensions=var.dimensions\n",
    "            )\n",
    "            new_var.setncatts({k: var.getncattr(k) for k in var.ncattrs()})\n",
    "            new_var[:] = var[:]\n",
    "            \n",
    "        ds2.title = 'combine file test'\n",
    "        ds2.setncattr('author','Yuhua Situ') #和上一行命令所用的方法等价\n",
    "        set_nc_attrs(ds2, './firecci_metadata.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
